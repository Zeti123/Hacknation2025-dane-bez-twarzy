{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a1ebd0a",
   "metadata": {},
   "source": [
    "wejście: surowy tekst (np. fragment dokumentu),\n",
    "wyjście: ustrukturyzowany wynik:\n",
    "\n",
    "\t•\ttokeny,\n",
    "\t•\tzdania,\n",
    "\t•\tPOS / tagi,\n",
    "\t•\tmorfologia (przypadek, liczba, rodzaj itd.),\n",
    "\t•\twstępne NER jako „hinty” dla kolejnych warstw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc68b771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.3/772.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.3-py3-none-any.whl (50 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading blis-1.3.3-cp310-cp310-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading wrapt-2.0.1-cp310-cp310-macosx_11_0_arm64.whl (61 kB)\n",
      "Installing collected packages: wrapt, wasabi, typing-inspection, typer-slim, tqdm, spacy-loggers, spacy-legacy, pydantic-core, murmurhash, cymem, cloudpathlib, catalogue, blis, annotated-types, srsly, smart-open, pydantic, preshed, confection, weasel, thinc, spacy\n",
      "Successfully installed annotated-types-0.7.0 blis-1.3.3 catalogue-2.0.10 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.13 murmurhash-1.0.15 preshed-3.0.12 pydantic-2.12.5 pydantic-core-2.41.5 smart-open-7.5.0 spacy-3.8.11 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.2 thinc-8.3.10 tqdm-4.67.1 typer-slim-0.20.0 typing-inspection-0.4.2 wasabi-1.1.3 weasel-0.4.3 wrapt-2.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n",
      "Collecting pl-core-news-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pl_core_news_md-3.8.0/pl_core_news_md-3.8.0-py3-none-any.whl (49.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m  \u001b[33m0:00:16\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pl_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download pl_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cd0d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Any, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce998d3",
   "metadata": {},
   "source": [
    "# Ładowanie spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1783b0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.pl.Polish at 0x12649d1c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"pl_core_news_md\")\n",
    "except OSError as e:\n",
    "    raise RuntimeError(\n",
    "        \"Polish model 'pl_core_news_md' is not installed. \"\n",
    "        \"Run: python -m spacy download pl_core_news_md\"\n",
    "    ) from e\n",
    "\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65729cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TokenInfo:\n",
    "    idx: int                 # token index in doc\n",
    "    text: str\n",
    "    lemma: str\n",
    "    pos: str                 # coarse POS tag\n",
    "    tag: str                 # detailed tag\n",
    "    morph: str               # raw morph string\n",
    "    dep: str                 # dependency relation\n",
    "    head: int                # index of head token\n",
    "    is_stop: bool\n",
    "    is_punct: bool\n",
    "    whitespace: str          # trailing whitespace\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SentenceInfo:\n",
    "    sent_id: int\n",
    "    text: str\n",
    "    start_char: int\n",
    "    end_char: int\n",
    "    token_indices: List[int]  # indices of tokens belonging to this sentence\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EntityHint:\n",
    "    text: str\n",
    "    label: str\n",
    "    start_char: int\n",
    "    end_char: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PreprocessResult:\n",
    "    raw_text: str\n",
    "    tokens: List[TokenInfo]\n",
    "    sentences: List[SentenceInfo]\n",
    "    entities: List[EntityHint]\n",
    "    meta: Dict[str, Any]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98742660",
   "metadata": {},
   "source": [
    "TokenInfo:\n",
    "\n",
    "\t•\tidx=i – numer tokena w dokumencie (int).\n",
    "\t•\ttext=token.text – oryginalny tekst tokena.\n",
    "\t•\tlemma=token.lemma_ – lemma (forma podstawowa) z pipeline’u spaCy.\n",
    "\t•\tpos=token.pos_ – ogólny POS (część mowy, np. NOUN, VERB).\n",
    "\t•\ttag=token.tag_ – szczegółowy tag morfosyntaktyczny (np. specyficzny tag UD).\n",
    "\t•\tmorph=token.morph.to_string() – cechy morfologiczne sklejone do jednego stringa, np. „Case=Nom|Number=Sing”.\n",
    "\t•\tdep=token.dep_ – relacja składniowa (dependency, np. nsubj, obj).\n",
    "\t•\thead=token.head.i – indeks tokena, który jest „headem” w drzewie zależności.\n",
    "\t•\tis_stop=token.is_stop – czy jest słowem funkcyjnym/stopword.\n",
    "\t•\tis_punct=token.is_punct – czy to znak interpunkcyjny.\n",
    "\t•\twhitespace=token.whitespace_ – oryginalny trailing whitespace (np. \" \", \"\\n\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88966212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea608c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacyPreprocessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"pl_core_news_md\",\n",
    "        use_ner_hints: bool = True,\n",
    "        disable: Optional[List[str]] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Wrapper around spaCy Polish pipeline.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_name : str\n",
    "            Name of the spaCy model to load.\n",
    "        use_ner_hints : bool\n",
    "            Whether to extract NER hints from spaCy doc.ents.\n",
    "        disable : list[str] | None\n",
    "            Optional list of pipeline components to disable for speed.\n",
    "            Example: [\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.use_ner_hints = use_ner_hints\n",
    "        self.disable = disable or []\n",
    "\n",
    "        # Load or reuse existing global nlp if possible\n",
    "        try:\n",
    "            self.nlp = spacy.load(model_name, disable=self.disable)\n",
    "        except OSError as e:\n",
    "            raise RuntimeError(\n",
    "                f\"spaCy model '{model_name}' is not installed. \"\n",
    "                f\"Install with: python -m spacy download {model_name}\"\n",
    "            ) from e\n",
    "\n",
    "    def _tokens_to_info(self, doc: \"spacy.tokens.Doc\") -> List[TokenInfo]:\n",
    "        tokens_info: List[TokenInfo] = []\n",
    "        for i, token in enumerate(doc):\n",
    "            tokens_info.append(\n",
    "                TokenInfo(\n",
    "                    idx=i,\n",
    "                    text=token.text,\n",
    "                    lemma=token.lemma_,\n",
    "                    pos=token.pos_,\n",
    "                    tag=token.tag_,\n",
    "                    morph=token.morph,\n",
    "                    dep=token.dep_,\n",
    "                    head=token.head.i,\n",
    "                    is_stop=token.is_stop,\n",
    "                    is_punct=token.is_punct,\n",
    "                    whitespace=token.whitespace_,\n",
    "                )\n",
    "            )\n",
    "        return tokens_info\n",
    "\n",
    "    def _sentences_to_info(self, doc: \"spacy.tokens.Doc\") -> List[SentenceInfo]:\n",
    "        sentences_info: List[SentenceInfo] = []\n",
    "        for sent_id, sent in enumerate(doc.sents):\n",
    "            token_indices = list(range(sent.start, sent.end))\n",
    "            sentences_info.append(\n",
    "                SentenceInfo(\n",
    "                    sent_id=sent_id,\n",
    "                    text=sent.text,\n",
    "                    start_char=sent.start_char,\n",
    "                    end_char=sent.end_char,\n",
    "                    token_indices=token_indices,\n",
    "                )\n",
    "            )\n",
    "        return sentences_info\n",
    "\n",
    "    def _entities_to_hints(self, doc: \"spacy.tokens.Doc\") -> List[EntityHint]:\n",
    "        entity_hints: List[EntityHint] = []\n",
    "        for ent in doc.ents:\n",
    "            entity_hints.append(\n",
    "                EntityHint(\n",
    "                    text=ent.text,\n",
    "                    label=ent.label_,\n",
    "                    start_char=ent.start_char,\n",
    "                    end_char=ent.end_char,\n",
    "                )\n",
    "            )\n",
    "        return entity_hints\n",
    "\n",
    "    def __call__(self, text: str) -> PreprocessResult:\n",
    "        \"\"\"\n",
    "        Run full preprocessing pipeline on raw text.\n",
    "        \"\"\"\n",
    "        doc = self.nlp(text)\n",
    "\n",
    "        tokens = self._tokens_to_info(doc)\n",
    "        sentences = self._sentences_to_info(doc)\n",
    "        entities = self._entities_to_hints(doc) if self.use_ner_hints else []\n",
    "\n",
    "        meta = {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"use_ner_hints\": self.use_ner_hints,\n",
    "            \"num_tokens\": len(tokens),\n",
    "            \"num_sentences\": len(sentences),\n",
    "            \"num_entities\": len(entities),\n",
    "        }\n",
    "\n",
    "        return PreprocessResult(\n",
    "            raw_text=text,\n",
    "            tokens=tokens,\n",
    "            sentences=sentences,\n",
    "            entities=entities,\n",
    "            meta=meta,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98164837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'pl_core_news_md',\n",
       " 'use_ner_hints': True,\n",
       " 'num_tokens': 21,\n",
       " 'num_sentences': 3,\n",
       " 'num_entities': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = \"\"\"\n",
    "Nazywam się Jan Kowalski, mój PESEL to 90010112345.\n",
    "Mieszkam w Warszawie przy ulicy Długiej 5.\n",
    "\"\"\"\n",
    "\n",
    "preprocessor = SpacyPreprocessor()\n",
    "result = preprocessor(example_text)\n",
    "\n",
    "result.meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "691e4684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0: \n",
      "               POS=SPACE TAG=_SP      MORPH=\n",
      " 1: Nazywam         POS=VERB  TAG=FIN      MORPH=Aspect=Imp|Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      " 2: się             POS=PRON  TAG=QUB      MORPH=PronType=Prs|Reflex=Yes\n",
      " 3: Jan             POS=PROPN TAG=SUBST    MORPH=Animacy=Hum|Case=Nom|Gender=Masc|Number=Sing\n",
      " 4: Kowalski        POS=PROPN TAG=SUBST    MORPH=Animacy=Hum|Case=Nom|Gender=Masc|Number=Sing\n",
      " 5: ,               POS=PUNCT TAG=INTERP   MORPH=PunctType=Comm\n",
      " 6: mój             POS=DET   TAG=ADJ      MORPH=Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing|Number[psor]=Sing|Person=1|Poss=Yes|PronType=Prs\n",
      " 7: PESEL           POS=PROPN TAG=SUBST    MORPH=Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
      " 8: to              POS=PRON  TAG=PRED     MORPH=Case=Nom|Gender=Neut|Number=Sing|PronType=Dem\n",
      " 9: 90010112345     POS=NUM   TAG=NUM      MORPH=Animacy=Inan|Case=Nom|Gender=Masc|NumForm=Digit|NumType=Card|Number=Sing\n",
      "10: .               POS=PUNCT TAG=SUBST    MORPH=PunctType=Peri\n",
      "11: \n",
      "               POS=SPACE TAG=_SP      MORPH=\n",
      "12: Mieszkam        POS=VERB  TAG=FIN      MORPH=Aspect=Imp|Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "13: w               POS=ADP   TAG=PREP     MORPH=AdpType=Prep|Variant=Short\n",
      "14: Warszawie       POS=PROPN TAG=SUBST    MORPH=Case=Loc|Gender=Fem|Number=Sing\n",
      "15: przy            POS=ADP   TAG=PREP     MORPH=AdpType=Prep\n",
      "16: ulicy           POS=NOUN  TAG=SUBST    MORPH=Case=Loc|Gender=Fem|Number=Sing\n",
      "17: Długiej         POS=ADJ   TAG=ADJ      MORPH=Case=Loc|Degree=Pos|Gender=Fem|Number=Sing\n",
      "18: 5               POS=X     TAG=NUM      MORPH=NumForm=Digit\n",
      "19: .               POS=PUNCT TAG=NUM      MORPH=PunctType=Peri\n"
     ]
    }
   ],
   "source": [
    "for t in result.tokens[:20]:\n",
    "    print(\n",
    "        f\"{t.idx:>2}: {t.text:<15} POS={t.pos:<5} TAG={t.tag:<8} MORPH={t.morph}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84f2196d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0: \n",
      "\n",
      "Sentence 1: Nazywam się Jan Kowalski, mój PESEL to 90010112345.\n",
      "\n",
      "Sentence 2: Mieszkam w Warszawie przy ulicy Długiej 5.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in result.sentences:\n",
    "    print(f\"Sentence {s.sent_id}: {s.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff0ef51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[persName] Jan Kowalski (13-25)\n",
      "[placeName] Warszawie (64-73)\n",
      "[geogName] ulicy Długiej (79-92)\n"
     ]
    }
   ],
   "source": [
    "for e in result.entities:\n",
    "    print(f\"[{e.label}] {e.text} ({e.start_char}-{e.end_char})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfa2549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = preprocessor(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f7dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'pl_core_news_md', 'use_ner_hints': True, 'num_tokens': 61, 'num_sentences': 6, 'num_entities': 5}\n",
      "--- TOKENS ---\n",
      "0 \n",
      " \n",
      " SPACE \n",
      "1 Reprezentujemy Reprezentujemy VERB Aspect=Imp|Mood=Ind|Number=Plur|Person=1|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "2 konsorcjum konsorcjum NOUN Case=Acc|Gender=Neut|Number=Sing\n",
      "3 DataSafe DataSafe ADV \n",
      "4 , , PUNCT PunctType=Comm\n",
      "5 które który DET Case=Nom|Gender=Neut|Number=Sing|PronType=Rel\n",
      "6 zajmuje zajmować VERB Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "7 się się PRON PronType=Prs|Reflex=Yes\n",
      "8 anonimizacją anonimizacja NOUN Case=Ins|Gender=Fem|Number=Sing\n",
      "9 dokumentów dokument NOUN Animacy=Inan|Case=Gen|Gender=Masc|Number=Plur\n",
      "10 . . PUNCT PunctType=Peri\n",
      "11 \n",
      " \n",
      " SPACE \n",
      "12 Siedziba Siedziba NOUN Case=Nom|Gender=Fem|Number=Sing\n",
      "13 firmy firma NOUN Case=Gen|Gender=Fem|Number=Sing\n",
      "14 znajduje znajdować VERB Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "15 się się PRON PronType=Prs|Reflex=Yes\n",
      "16 we w ADP AdpType=Prep|Variant=Long\n",
      "17 Wrocławiu Wrocław PROPN Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\n",
      "18 przy przy ADP AdpType=Prep\n",
      "19 ulicy ulica NOUN Case=Loc|Gender=Fem|Number=Sing\n",
      "20 Kościuszki Kościuszko PROPN Animacy=Hum|Case=Gen|Gender=Masc|Number=Sing\n",
      "21 10 10 ADJ Case=Gen|Degree=Pos|Gender=Fem|NumForm=Digit|NumType=Ord|Number=Sing\n",
      "22 . . PUNCT PunctType=Peri\n",
      "23 \n",
      " \n",
      " SPACE \n",
      "24 Dane dana NOUN Case=Nom|Gender=Fem|Number=Plur\n",
      "25 osobowe osobowy ADJ Case=Nom|Degree=Pos|Gender=Fem|Number=Plur\n",
      "26 takich taki DET Case=Gen|Gender=Fem|Number=Plur|PronType=Dem\n",
      "27 osób osoba NOUN Case=Gen|Gender=Fem|Number=Plur\n",
      "28 jak jak SCONJ ConjType=Comp\n",
      "29 Jan Jan PROPN Animacy=Hum|Case=Nom|Gender=Masc|Number=Sing\n",
      "30 Kowalski Kowalski PROPN Animacy=Hum|Case=Nom|Gender=Masc|Number=Sing\n",
      "31 czy czy CCONJ \n",
      "32 Anna Anna PROPN Case=Nom|Gender=Fem|Number=Sing\n",
      "33 Nowak Nowak PROPN Case=Nom|Gender=Fem|Number=Sing\n",
      "34 muszą musieć VERB Aspect=Imp|Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "35 zostać zostać AUX Aspect=Perf|VerbForm=Inf|Voice=Act\n",
      "36 zanonimizowane zanonimizować ADJ Aspect=Perf|Case=Nom|Gender=Fem|Number=Plur|Polarity=Pos|VerbForm=Part|Voice=Pass\n",
      "37 . . PUNCT PunctType=Peri\n",
      "38 Mój mój DET Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing|Number[psor]=Sing|Person=1|Poss=Yes|PronType=Prs\n",
      "39 nr numer X Abbr=Yes|Pun=No\n",
      "40 telefonu telefon NOUN Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
      "41 to to AUX Mood=Ind|Tense=Pres|VerbForm=Fin|VerbType=Quasi\n",
      "42 123 123 ADJ Case=Nom|Degree=Pos|Gender=Neut|Number=Sing\n",
      "43 - - PUNCT PunctType=Dash\n",
      "44 456 456 PROPN Case=Nom|Gender=Neut|Number=Sing\n",
      "45 - - PUNCT PunctType=Dash\n",
      "46 789 789 PROPN Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
      "47 . . PUNCT PunctType=Peri\n",
      "48 Nazywam Nazywam VERB Aspect=Imp|Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "49 się się PRON PronType=Prs|Reflex=Yes\n",
      "50 Krawiec Krawiec NOUN Animacy=Hum|Case=Nom|Gender=Masc|Number=Sing\n",
      "51 i i CCONJ \n",
      "52 urodziłem urodzić być VERB Animacy=Hum|Aspect=Imp,Perf|Clitic=Yes|Gender=Masc|Mood=Ind|Number=Sing|Person=1|Tense=Past|Variant=Long|VerbForm=Fin|Voice=Act\n",
      "53 się się PRON PronType=Prs|Reflex=Yes\n",
      "54 20 20 NUM Animacy=Inan|Case=Acc|Gender=Masc|NumForm=Digit|NumType=Card|Number=Plur\n",
      "55 - - PUNCT PunctType=Dash\n",
      "56 10 10 ADJ Case=Nom|Degree=Pos|Gender=Fem|NumForm=Digit|NumType=Ord|Number=Sing\n",
      "57 - - PUNCT PunctType=Dash\n",
      "58 2024 2024 X NumForm=Digit\n",
      "59 . . PUNCT PunctType=Peri\n",
      "60 \n",
      " \n",
      " SPACE \n",
      "--- ENTITIES ---\n",
      "placeName -> Wrocławiu\n",
      "geogName -> ulicy\n",
      "persName -> Jan Kowalski\n",
      "persName -> Anna Nowak\n",
      "persName -> Krawiec\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "\"Reprezentujemy konsorcjum DataSafe, które zajmuje się anonimizacją dokumentów. \"\n",
    "\"Siedziba firmy znajduje się we Wrocławiu przy ulicy Kościuszki 10. \"\n",
    "\"Dane osobowe takich osób jak Jan Kowalski czy Anna Nowak muszą zostać zanonimizowane. \"\n",
    "\"Mój nr telefonu to 123-456-789. Nazywam się Krawiec i urodziłem się 20-10-2024.\"\n",
    "\"\"\"\n",
    "\n",
    "preprocessor = SpacyPreprocessor()\n",
    "result = preprocessor(text)\n",
    "\n",
    "print(result.meta)\n",
    "print(\"--- TOKENS ---\")\n",
    "for t in result.tokens:\n",
    "    print(t.idx, t.text, t.lemma, t.pos, t.morph)\n",
    "\n",
    "print(\"--- ENTITIES ---\")\n",
    "for e in result.entities:\n",
    "    print(e.label, \"->\", e.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "863bf785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EntityHint(text='Wrocławiu', label='placeName', start_char=111, end_char=120),\n",
       " EntityHint(text='ulicy', label='geogName', start_char=126, end_char=131),\n",
       " EntityHint(text='Jan Kowalski', label='persName', start_char=173, end_char=185),\n",
       " EntityHint(text='Anna Nowak', label='persName', start_char=190, end_char=200),\n",
       " EntityHint(text='Krawiec', label='persName', start_char=274, end_char=281)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.entities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
