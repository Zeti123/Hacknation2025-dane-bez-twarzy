{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a1ebd0a",
   "metadata": {},
   "source": [
    "wejście: surowy tekst (np. fragment dokumentu),\n",
    "wyjście: ustrukturyzowany wynik:\n",
    "\n",
    "\t•\ttokeny,\n",
    "\t•\tzdania,\n",
    "\t•\tPOS / tagi,\n",
    "\t•\tmorfologia (przypadek, liczba, rodzaj itd.),\n",
    "\t•\twstępne NER jako „hinty” dla kolejnych warstw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc68b771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.11-cp312-cp312-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.15-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.3 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.13-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.12-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.10-cp312-cp312-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.4.2 (from spacy)\n",
      "  Downloading weasel-0.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0 (from spacy)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Downloading numpy-2.3.5-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting requests<3.0.0,>=2.13.0 (from spacy)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting jinja2 (from spacy)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting setuptools (from spacy)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from spacy) (25.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typing-extensions>=4.14.1 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading urllib3-2.6.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting click>=8.0.0 (from typer-slim<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading wrapt-2.0.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->spacy)\n",
      "  Downloading markupsafe-3.0.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Downloading spacy-3.8.11-cp312-cp312-macosx_11_0_arm64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m eta \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.13-cp312-cp312-macosx_11_0_arm64.whl (42 kB)\n",
      "Downloading murmurhash-1.0.15-cp312-cp312-macosx_11_0_arm64.whl (27 kB)\n",
      "Downloading preshed-3.0.12-cp312-cp312-macosx_11_0_arm64.whl (124 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl (208 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.2-cp312-cp312-macosx_11_0_arm64.whl (653 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.2/653.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.10-cp312-cp312-macosx_11_0_arm64.whl (741 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m741.1/741.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading blis-1.3.3-cp312-cp312-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading numpy-2.3.5-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading urllib3-2.6.0-py3-none-any.whl (131 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.3-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Downloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading wrapt-2.0.1-cp312-cp312-macosx_11_0_arm64.whl (61 kB)\n",
      "Installing collected packages: wrapt, wasabi, urllib3, typing-extensions, tqdm, spacy-loggers, spacy-legacy, setuptools, numpy, murmurhash, MarkupSafe, idna, cymem, cloudpathlib, click, charset_normalizer, certifi, catalogue, annotated-types, typing-inspection, typer-slim, srsly, smart-open, requests, pydantic-core, preshed, jinja2, blis, pydantic, confection, weasel, thinc, spacy\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/33\u001b[0m [spacy]m32/33\u001b[0m [spacy]ic]s]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 annotated-types-0.7.0 blis-1.3.3 catalogue-2.0.10 certifi-2025.11.12 charset_normalizer-3.4.4 click-8.3.1 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.13 idna-3.11 jinja2-3.1.6 murmurhash-1.0.15 numpy-2.3.5 preshed-3.0.12 pydantic-2.12.5 pydantic-core-2.41.5 requests-2.32.5 setuptools-80.9.0 smart-open-7.5.0 spacy-3.8.11 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.2 thinc-8.3.10 tqdm-4.67.1 typer-slim-0.20.0 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.6.0 wasabi-1.1.3 weasel-0.4.3 wrapt-2.0.1\n",
      "Collecting pl-core-news-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pl_core_news_md-3.8.0/pl_core_news_md-3.8.0-py3-none-any.whl (49.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m  \u001b[33m0:00:22\u001b[0mm0:00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: pl-core-news-md\n",
      "Successfully installed pl-core-news-md-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pl_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download pl_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd0d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Any, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce998d3",
   "metadata": {},
   "source": [
    "# Ładowanie spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1783b0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.pl.Polish at 0x107932ba0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"pl_core_news_md\")\n",
    "except OSError as e:\n",
    "    raise RuntimeError(\n",
    "        \"Polish model 'pl_core_news_md' is not installed. \"\n",
    "        \"Run: python -m spacy download pl_core_news_md\"\n",
    "    ) from e\n",
    "\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65729cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TokenInfo:\n",
    "    idx: int                 # token index in doc\n",
    "    text: str\n",
    "    lemma: str\n",
    "    pos: str                 # coarse POS tag\n",
    "    tag: str                 # detailed tag\n",
    "    morph: str               # raw morph string\n",
    "    dep: str                 # dependency relation\n",
    "    head: int                # index of head token\n",
    "    is_stop: bool\n",
    "    is_punct: bool\n",
    "    whitespace: str          # trailing whitespace\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SentenceInfo:\n",
    "    sent_id: int\n",
    "    text: str\n",
    "    start_char: int\n",
    "    end_char: int\n",
    "    token_indices: List[int]  # indices of tokens belonging to this sentence\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EntityHint:\n",
    "    text: str\n",
    "    label: str\n",
    "    start_char: int\n",
    "    end_char: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PreprocessResult:\n",
    "    raw_text: str\n",
    "    tokens: List[TokenInfo]\n",
    "    sentences: List[SentenceInfo]\n",
    "    entities: List[EntityHint]\n",
    "    meta: Dict[str, Any]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea608c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacyPreprocessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"pl_core_news_md\",\n",
    "        use_ner_hints: bool = True,\n",
    "        disable: Optional[List[str]] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Wrapper around spaCy Polish pipeline.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_name : str\n",
    "            Name of the spaCy model to load.\n",
    "        use_ner_hints : bool\n",
    "            Whether to extract NER hints from spaCy doc.ents.\n",
    "        disable : list[str] | None\n",
    "            Optional list of pipeline components to disable for speed.\n",
    "            Example: [\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.use_ner_hints = use_ner_hints\n",
    "        self.disable = disable or []\n",
    "\n",
    "        # Load or reuse existing global nlp if possible\n",
    "        try:\n",
    "            self.nlp = spacy.load(model_name, disable=self.disable)\n",
    "        except OSError as e:\n",
    "            raise RuntimeError(\n",
    "                f\"spaCy model '{model_name}' is not installed. \"\n",
    "                f\"Install with: python -m spacy download {model_name}\"\n",
    "            ) from e\n",
    "\n",
    "    def _tokens_to_info(self, doc: \"spacy.tokens.Doc\") -> List[TokenInfo]:\n",
    "        tokens_info: List[TokenInfo] = []\n",
    "        for i, token in enumerate(doc):\n",
    "            tokens_info.append(\n",
    "                TokenInfo(\n",
    "                    idx=i,\n",
    "                    text=token.text,\n",
    "                    lemma=token.lemma_,\n",
    "                    pos=token.pos_,\n",
    "                    tag=token.tag_,\n",
    "                    morph=token.morph,\n",
    "                    dep=token.dep_,\n",
    "                    head=token.head.i,\n",
    "                    is_stop=token.is_stop,\n",
    "                    is_punct=token.is_punct,\n",
    "                    whitespace=token.whitespace_,\n",
    "                )\n",
    "            )\n",
    "        return tokens_info\n",
    "\n",
    "    def _sentences_to_info(self, doc: \"spacy.tokens.Doc\") -> List[SentenceInfo]:\n",
    "        sentences_info: List[SentenceInfo] = []\n",
    "        for sent_id, sent in enumerate(doc.sents):\n",
    "            token_indices = list(range(sent.start, sent.end))\n",
    "            sentences_info.append(\n",
    "                SentenceInfo(\n",
    "                    sent_id=sent_id,\n",
    "                    text=sent.text,\n",
    "                    start_char=sent.start_char,\n",
    "                    end_char=sent.end_char,\n",
    "                    token_indices=token_indices,\n",
    "                )\n",
    "            )\n",
    "        return sentences_info\n",
    "\n",
    "    def _entities_to_hints(self, doc: \"spacy.tokens.Doc\") -> List[EntityHint]:\n",
    "        entity_hints: List[EntityHint] = []\n",
    "        for ent in doc.ents:\n",
    "            entity_hints.append(\n",
    "                EntityHint(\n",
    "                    text=ent.text,\n",
    "                    label=ent.label_,\n",
    "                    start_char=ent.start_char,\n",
    "                    end_char=ent.end_char,\n",
    "                )\n",
    "            )\n",
    "        return entity_hints\n",
    "\n",
    "    def __call__(self, text: str) -> PreprocessResult:\n",
    "        \"\"\"\n",
    "        Run full preprocessing pipeline on raw text.\n",
    "        \"\"\"\n",
    "        doc = self.nlp(text)\n",
    "\n",
    "        tokens = self._tokens_to_info(doc)\n",
    "        sentences = self._sentences_to_info(doc)\n",
    "        entities = self._entities_to_hints(doc) if self.use_ner_hints else []\n",
    "\n",
    "        meta = {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"use_ner_hints\": self.use_ner_hints,\n",
    "            \"num_tokens\": len(tokens),\n",
    "            \"num_sentences\": len(sentences),\n",
    "            \"num_entities\": len(entities),\n",
    "        }\n",
    "\n",
    "        return PreprocessResult(\n",
    "            raw_text=text,\n",
    "            tokens=tokens,\n",
    "            sentences=sentences,\n",
    "            entities=entities,\n",
    "            meta=meta,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98164837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'pl_core_news_md',\n",
       " 'use_ner_hints': True,\n",
       " 'num_tokens': 21,\n",
       " 'num_sentences': 3,\n",
       " 'num_entities': 3}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = \"\"\"\n",
    "Nazywam się Jan Kowalski, mój PESEL to 90010112345.\n",
    "Mieszkam w Warszawie przy ulicy Długiej 5.\n",
    "\"\"\"\n",
    "\n",
    "preprocessor = SpacyPreprocessor()\n",
    "result = preprocessor(example_text)\n",
    "\n",
    "result.meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "691e4684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0: \n",
      "               POS=SPACE TAG=_SP      MORPH=\n",
      " 1: Nazywam         POS=VERB  TAG=FIN      MORPH=Aspect=Imp|Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      " 2: się             POS=PRON  TAG=QUB      MORPH=PronType=Prs|Reflex=Yes\n",
      " 3: Jan             POS=PROPN TAG=SUBST    MORPH=Animacy=Hum|Case=Nom|Gender=Masc|Number=Sing\n",
      " 4: Kowalski        POS=PROPN TAG=SUBST    MORPH=Animacy=Hum|Case=Nom|Gender=Masc|Number=Sing\n",
      " 5: ,               POS=PUNCT TAG=INTERP   MORPH=PunctType=Comm\n",
      " 6: mój             POS=DET   TAG=ADJ      MORPH=Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing|Number[psor]=Sing|Person=1|Poss=Yes|PronType=Prs\n",
      " 7: PESEL           POS=PROPN TAG=SUBST    MORPH=Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
      " 8: to              POS=PRON  TAG=PRED     MORPH=Case=Nom|Gender=Neut|Number=Sing|PronType=Dem\n",
      " 9: 90010112345     POS=NUM   TAG=NUM      MORPH=Animacy=Inan|Case=Nom|Gender=Masc|NumForm=Digit|NumType=Card|Number=Sing\n",
      "10: .               POS=PUNCT TAG=SUBST    MORPH=PunctType=Peri\n",
      "11: \n",
      "               POS=SPACE TAG=_SP      MORPH=\n",
      "12: Mieszkam        POS=VERB  TAG=FIN      MORPH=Aspect=Imp|Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "13: w               POS=ADP   TAG=PREP     MORPH=AdpType=Prep|Variant=Short\n",
      "14: Warszawie       POS=PROPN TAG=SUBST    MORPH=Case=Loc|Gender=Fem|Number=Sing\n",
      "15: przy            POS=ADP   TAG=PREP     MORPH=AdpType=Prep\n",
      "16: ulicy           POS=NOUN  TAG=SUBST    MORPH=Case=Loc|Gender=Fem|Number=Sing\n",
      "17: Długiej         POS=ADJ   TAG=ADJ      MORPH=Case=Loc|Degree=Pos|Gender=Fem|Number=Sing\n",
      "18: 5               POS=X     TAG=NUM      MORPH=NumForm=Digit\n",
      "19: .               POS=PUNCT TAG=NUM      MORPH=PunctType=Peri\n"
     ]
    }
   ],
   "source": [
    "for t in result.tokens[:20]:\n",
    "    print(\n",
    "        f\"{t.idx:>2}: {t.text:<15} POS={t.pos:<5} TAG={t.tag:<8} MORPH={t.morph}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84f2196d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0: \n",
      "\n",
      "Sentence 1: Nazywam się Jan Kowalski, mój PESEL to 90010112345.\n",
      "\n",
      "Sentence 2: Mieszkam w Warszawie przy ulicy Długiej 5.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in result.sentences:\n",
    "    print(f\"Sentence {s.sent_id}: {s.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ff0ef51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[persName] Jan Kowalski (13-25)\n",
      "[placeName] Warszawie (64-73)\n",
      "[geogName] ulicy Długiej (79-92)\n"
     ]
    }
   ],
   "source": [
    "for e in result.entities:\n",
    "    print(f\"[{e.label}] {e.text} ({e.start_char}-{e.end_char})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa2549d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
